<html>
  <head>
    <meta charset="utf-8">
    <link rel="shortcut icon" href="images/icons/favicon.ico"/>
    <link rel="stylesheet" href="css/insite.css">
    <link rel="stylesheet" href="css/navbar.css">
    <link rel="stylesheet" href="css/footer.css">
    <title>INsite Lab Research</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="google-site-verification" content="MkOG3xvxvculEQ2ZUNVf_52CdnKHvDZGGKrI6ylI2eY" />
    <link href="https://fonts.googleapis.com/css?family=Lato:300,300i,400,400i,700,700i,900,900i&display=swap" rel="stylesheet">
    <script src="https://kit.fontawesome.com/df959595e9.js" crossorigin="anonymous"></script>
  </head>
<body>
  <div class="main">
    <div class="navbar">
      <div class="overlay" id="overlay"></div>
      <div class="home-hamburger-container">
        <a href="index.html">
          <div class="home-link">AT</div>
        </a>
        <div class="hamburger-icon" id="hamburger">
          <svg class="hamburger-svg" width="28" height="22">
            <rect class="bar" id="bar1" x="0" y="0" width="28" height="4" rx="2" style="fill:white"/>
            <rect class="bar" id="bar2" x="0" y="9" width="28" height="4" rx="2" style="fill:white"/>
            <rect class="bar" id="bar3" x="0" y="18" width="28" height="4" rx="2" style="fill:white"/>
          </svg>
        </div>
      </div>
      <div class="links" id="links">
        <a href="index.html#Work" class="link closed" id="work-link">Work<div class="link-line" id="work-line"></div></a>
        <a href="about.html" class="link closed" id="about-link">About<div class="link-line" id="about-line"></div></a>
        <a href="contact.html" class="link closed" id="contact-link">Contact<div class="link-line" id="contact-line"></div></a>
      </div>  
    </div>
    <div class="project-card resize" id="project-card">
      <div class="title">
        <img class="project-logo" src="images/logos/toyota-logo.png">
        <h>UX Research to Promote Mobility for All</h>
      </div>
      <div class="project-info" id="info1">
        <p class="info-title"><b>Role</b></p>
        <p>UX Research Assistant, Prototype Team Lead</p>
      </div>
      <div class="project-info" id="info2">
        <p class="info-title"><b>Time Frame</b></p>
        <p>July 2019 - Present</p>
      </div>
      <div class="project-info" id="info3">
        <p class="info-title"><b>Methods</b></p>
        <p>User Interviews, Affinity Diagrams, User Personas, User Scenarios, Design Spaces, Prototyping</p>
      </div>
      <div class="project-info" id="info4">
        <p class="info-title"><b>Tools</b></p>
        <p>Adobe Illustrator, Adobe Photoshop, Miro/RealTimeBoard</p>
      </div>
    </div>
  </div>
  
  <div class="project-container">
    <div class="context">
      <h1>Project Context</h1>
      <div class="sub-img">
        <img class="image" src="images/insite/insite-full.png">
      </div>
      <p class="full-width">Since July 2019, I have had the opportunity of working as part of the INsite Lab led by Dr. Stacy Branham of UC Irvine. With the partnership of Toyota Motor North America and collaboration of the University of Maryland, Baltimore County, we are conducting research to design assistive technology prototypes that provide navigational support for older adults with disabilities. This project aims to promote mobility for all and puts focus on a broad range of disabilities to understand how the navigational preferences of individuals in diverse groups may overlap or differ in various situations. </p>
    </div>
    <div class="user-research">
      <h1>User Research</h1>
      <p class="full-width">We conducted an interview study with 27 people of varying ages and disabilities to gain understanding of wayfinding in their daily lives. The participants represented five different ability-based identities, with most of them having multiple disability identities:</p>
      <div class="sub-img">
        <img class="image" src="images/insite/identities.png">
      </div>
      <p class="full-width">Primarily, we wanted to see what kinds of challenges or strategies are encountered by those with intersecting disabilities (for example, an older adult with visual impairment) and how navigation technology can be better designed for people across disability identities. People across and at intersecting disabilities shared many mobility needs, such as the desire to seek out landmarks or points of interest and to avoid particular surfaces or features that will affect their mobility. Specifically, the important navigational cues several participants noted were crowded areas, carpeted surfaces, stairs, ramps, seasonal challenges, construction, and signage.</p>
      <p class="full-width">Most of the issues participants shared were associated to exploratory wayfinding rather than step-by-step wayfinding or routing. Participants found it necessary to be notified of any of the potential hazards or landmarks mentioned previously to have a better navigating experience, especially in areas they are unfamiliar with. </p>
    </div>
    <div class="user-personas">
      <h1>User Personas</h1>
      <p class="full-width">It is important to keep in mind the participantsâ€™ challenges, strategies, needs, and preferences throughout the design process, so we wanted to represent the patterns we found in the interviews in the form of personas. Based on the types of responses, we determined four specific preferences or dichotomies that we could use to categorize users:</p>
      <ul class="sub-width">
        <li>Human (H) vs Technological (T) Assistance</li>
        <li>Planned (P) vs Spntaneous (S) Routes</li>
        <li>Familiar (F) vs Latest (L) Technologies</li>
        <li>Enjoyable (En) vs Efficient (Ef) Experiences</li>
      </ul>
      <p class="full-width">Taking inspiration from the Myers-Briggs personality types, we used these preferences to generate acronyms and identify 16 different possible navigation personalities, of which there were four that were common among participants: HPFEn, TPFEn, TPLEf, TSLEf. These personality types were given the personas of Alice, Rachel, Brandon, and Omar respectively, each representing a different set of disability identities and given goals, desires, painpoints, and other realistic qualities that were sourced from our interview data.</p>
      <p class="full-width">For example, Alice Hughes is a 67 year old retired woman with a visual impairment. She can perceive colors especially in bright conditions and utilizes light sources to help her wayfind. Alice relies only on technology that is familiar to her and needs people around to provide her step-by-step routes to places she wants to go to, primarily travelling with companions to places. Knowing the road conditions and where particular landmarks such as stairs, elevators, or any obstacles are on the way are important for her to travel safely. She prefers enjoyable experiences when travelling and will avoid crowded areas.</p>
      <div class="wide-img">
        <img class="image" src="images/insite/alice.png">
      </div>
      <p class="full-width">These personas will allow our design teams to have a shared understanding of the participants that we will be designing for, and will facilitate discussions over what features are important to include in our designs and why.</p>
    </div>
    <div class="design-spaces">
      <h1>Design Spaces</h1>
      <p class="full-width">Before designing, we wanted to look at the various assistive technologies available in the market to create design spaces. A design space is much like a competitor analysis, and is a technique that essentially evaluates products based on various design criteria, which allows us to gain an understanding of how needs are met by current technologies and if there were any opportunities for new ideas. We analyzed nearly 40 different products such as smartphone apps like <a href="https://tech.aph.org/neandroid/">Nearby Explorer</a> and <a href="https://apps.apple.com/us/app/be-my-eyes/id905177575">Be My Eyes</a>, hardware like <a href="https://imerciv.com/">BuzzClip</a> and <a href="http://www.humanware.com/microsite/bntouch/index.php">BrailleNote</a>, and even devices made by other research groups. We looked at a wide range of features, and based on those features, we evaluated the products and plotted them on two-dimensional charts like the one shown below.</p>
      <div class="full-img">
        <img class="image" src="images/insite/design-space.png">
      </div>
      <p class="full-width">This particular chart evaluates the products based on whether they supported indoor or outdoor navigation and whether they provided step-by-step directions or promoted exploratory wayfinding. A blue background is used to visibly highlight empty spots in the graph, where there may be opportunity for new designs. 50% of the products occupy the bottom half of the chart and leaned to the right, indicating that products support exploratory wayfinding outdoors, gaining environmental awareness, and navigating with the purpose of exploring a space rather than pursuing a specific route to a predetermined destination. This suggests that there is a lack of technologies that support predetermined routes, especially indoors, which is understandable since mapping building interiors can be an arduous task.</p>
      <p class="full-width">When we looked at the applications that were supposed to provide environmental awareness, we found that they did not support many of the features that our interview study found to be important. To demonstrate this, we created a table that identifies whether specific environmental awareness features were present in the products. We noticed that features that were lacking in our table were detection of crowds, significant noise, shifts in light, carpet, and ability to read signage, and the only products that incorporated these were live-assistant based (e.g. Aira, Be My Eyes).</p>
      <div class="sub-img">
        <img class="image" src="images/insite/features-table.png">
      </div>
      <p class="full-width">We also looked at the types of input and output modalities or formats offered by each app which is important to consider when helping those of varying disabilities. Similarly, we found that exploratory awareness apps were missing key interaction features that could improve the hands-free, eyes-free experience that is important when navigating with or without assistive technology. Features that were lacking in our table were audio input in the form of voice commands, audio output in the form of earcons (e.g. beeps, buzzing, notification sounds, etc.), touch-based input like gestures, and touch-based output in the form of tactons (e.g. braille, vibrations, etc.). <a href="https://dl.acm.org/doi/10.5555/1124635.1124644">Previous research</a> has shown that these modalities, especially when combined into multimodal interfaces, are valued by people with disabilities who may be navigating.</p>
      <div class="sub-img">
        <img class="image" src="images/insite/modalities-table.png">
      </div>
      <p class="full-width">Putting together the findings from the various design space representations, we identified specific technological opportunities listed below and will focus on designing technologies for exploratory wayfinding that make better use of these features.</p>
      <div class="sub-img">
        <img class="image" src="images/insite/design-opportunities.png">
      </div>
    </div>
    <div class="user-scenarios">
      <h1>User Scenarios</h1>
      <p class="full-width">Thus far we have created user personas to represent the types of people we are designing for and identified technological opportunities. In order to easily imagine and brainstorm potential prototypes, we have created several scenarios that utilize the personas we developed and will address different opportunities. For example, here is a scenario that describes Alice Hughes exploring an airport:</p>
      <p class="sub-width"><i>Alice is 67 years old. She is visiting her children and grandchildren for the holidays. So, most tickets were sold out, but she managed to get a ticket with a 4 hour layover at an airport she has never visited before. Within the layover time, she would like to shop for her family, grab dinner, and find places with charging ports for her device. Additionally, she prefers to complete most activities near the departure gate so that she can be on time for the flight. She is aware of the presence of visual maps <b>[accessible maps]</b> with information on the facilities, shops and directions, but, these maps are not accessible because of her visual impairment. She also likes to ask questions of airport staff, but they are hard to find and are not always available when needed <b>[voice assistant]</b>. She wishes that she could get a hold on the information provided by the maps through accessible technology on her device.</i></p>
      <p class="full-width">This scenario puts Alice in a situation that addresses the technological opportunities of accessible maps and voice assistants, applying the desires and personality traits that we defined previously for her. We want to use this situation to explore what kind of information would be most important to represent in a map to a user, and how a user would be able to interact with a digital map representation solely through voice interactions. Using this and other scenarios, we want to help designers better empathize with the contextual needs of their target users, which will greatly assist in the brainstorming process.</p>
    </div>
    <div class="next-steps">
      <h1>Next Steps</h1>
      <p class="full-width">Right now, we are in the process of designing potential prototypes for these scenarios and identifying what type of features we think would be important to include. We will then be creating both hosting several co-design sessions with participants to gauge their interest in and get their input on the prototypes with regards to its features, interaction design, form factor, and other criteria.</p>
    </div>
  </div>

  <footer>
    <div class="footer-container">
      <a class="footer-logo" href="index.html"><h>AndrewTumang</h></a>
      <div class="footer-icons">
        <a href="https://github.com/andrewtumang"><img class="footer-icon" src="images/icons/github.svg"></a>
        <a href="https://www.linkedin.com/in/andrewtumang/"><img class="footer-icon" src="images/icons/linkedin.svg"></a>
        <a href="mailto:hello@andrewtumang.com"><img class="footer-icon" src="images/icons/email.svg"></a>
      </div>
      <p class="footer-comment">
        Designed and coded from scratch by Andrew Tumang
      </p>
    </div>
  </footer>
  
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="./js/case-study.js"></script>
  <script src="./js/navbar.js"></script>
</body>
</html>